# AI Pipelines to improve feature quality

## Pipeline 1: Semantic Search

### Phase A: Indexing Phase (Offline Processing)

-  **Step 1: Document Ingestion:** A new document (PDF, DOCX) is uploaded via the Frontend.
-  **Step 2: Preprocessing:** The text will be extracted from the document using XLSX Reader (for DOCX) or LLM Text Extraction Model (for PDF). The text is then divided into smaller, meaningful "chunks" (e.g., individual articles, clauses, or paragraphs). This is a critical step; good chunking improves search relevance.
-  **Step 3: Embedding Generation:** Each chunk is converted into a vector representation using a pre-trained model (sentence-BERT, Qwen, etc.).
-  **Step 4: Vector Storage:** The generated vector, along with a reference to its source document and chunk ID, is stored in the Qdrant Vector Database.

**Visual Flow:** `[Document File] -> [Parsing/Chunking Service] -> [Embedding Model] -> [Qdrant Vector DB]`

### Phase B: Querying Phase (Realtime)

-  **Step 1: User Query:** A user query is submitted via the Frontend Search Bar, for example "ID issuance process".
-  **Step 2: Query Processing:** The user's query string is sent to the same Embedding Model used in the indexing phase. This converts the query into a vector.
-  **Step 3: Retrieval:** The query vector is used to perform a similarity search against all the vectors stored in the Qdrant Vector Database. Qdrant efficiently calculates the "distance" between the query vector and all document vectors, returning the top-K most similar results (e.g., the top 20 most relevant chunks).
-  **Step 4: Response Presentation:** The system retrieves the original text chunks corresponding to the top-K results and presents them to the user, highlighting the relevant sections and providing links to the full documents.

**Visual Flow:** `[User Query] -> [Embedding Model] -> [Qdrant Vector DB] -> [Frontend]`

## Pipeline 2: Automated Information Extraction

-  **Step 1 & 2: Document Ingestion and Preprocessing:** Same with Pipeline 1, Step 1 & 2.
-  **Step 3: LLM Prompting for Extraction:** The system constructs a specific prompt and sends it to the LLM Serving Engine. This is a zero-shot or few-shot prompting technique.

    **Prompt Example:**
    ```text
    Given the following legal document text, extract the specified entities. Respond in JSON format only.

    Entities to extract:
    - "signer_name": The full name of the person who signed the document.
    - "issue_date": The date the document was issued, in YYYY-MM-DD format.
    - "document_class": The classification of the document (e.g., "Decree", "Circular", "Law").

    Document Text:
    """
    [Full text of the legal document is inserted here]
    """
    ```
-  **Step 4: JSON Response Parsing:** The Legal LLM parses the text and returns a structured JSON object as requested.

    **Example Response:**
    ```json
    {
      "signer_name": "Nguyen Van A",
      "issue_date": "2023-10-27",
      "document_class": "Decree"
    }
    ```
-  **Step 5: Populate UI:** The backend service parses this JSON and uses the data to pre-fill the metadata fields on the Frontend. The user then simply verifies the information and saves the document.

## Pipeline 3: Efficient Document Comparison (Similarity & Conflict Detection)

-  **Step 1: Input Definition:**
    - User chooses an existing document or uploads a new document via the Frontend.
    - User can choose to include all document content or only a selected part of the document.
    - This selected text will serve as the reference basis.
-  **Step 2: Retrieval Phase:**
    The system takes the selected context (e.g., Article 5 of Document A or the entire Document A), splits it into chunks, and generates an embedding for each chunk. It then performs a similarity search against the Qdrant Vector Database for each chunk of the reference basis, returning the top-K most similar results for each chunk.
-  **Step 3: Augmentation and Generation Phase:**
    A sophisticated prompt is constructed and sent to the LLM Serving Engine. This prompt is "augmented" with the retrieved context.

    **Prompt Example:**
    ```text
    You are an expert legal assistant. Your task is to analyze a primary clause and compare it against a set of related clauses to identify any conflicts, similarities, or overlaps.

    **Primary Clause:**
    "[Text of Article 5, Document A]"

    **Related Clauses (for context):**
    1. "[Text of retrieved chunk 1]"
    2. "[Text of retrieved chunk 2]"
    3. "[Text of retrieved chunk 3]"
    ...

    **Analysis Request:**
    Based on the provided context, perform the following:
    1. Identify any clauses that are in direct **conflict** with the Primary Clause.
    2. Identify any clauses that are highly **similar** or redundant to the Primary Clause.
    3. For each finding, provide a brief explanation and cite the specific documents and clauses involved.
    Respond in a structured JSON format.
    ```
-  **Step 4: Structured Analysis Output:**
    The LLM processes this complex request and returns a structured analysis.

    **Example Response:**
    ```json
    {
      "findings": [
        {
          "type": "Conflict",
          "explanation": "The Primary Clause permits action X, whereas Article 12 of Document Y explicitly prohibits action X under similar conditions.",
          "source_clause": { "document_id": "A", "clause": "Article 5" },
          "conflicting_clause": { "document_id": "Y", "clause": "Article 12" }
        },
        {
          "type": "Similarity",
          "explanation": "The content of the Primary Clause is nearly identical to the content of Section 3.2 of Document Z.",
          "source_clause": { "document_id": "A", "clause": "Article 5" },
          "similar_clause": { "document_id": "Z", "clause": "Section 3.2" }
        }
      ]
    }
    ```
-  **Step5: Interactive Review Workbench:** This structured JSON is used to populate the "Review Workbench" UI. Each "finding" is displayed as an interactive card. When a user clicks on a card, the UI can automatically display the two relevant clauses side-by-side for immediate comparison and verification.